{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install BeautifulSoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data preprocessing\n",
    "pd.set_option('display.max_rows', None)# To show all the rows of pandas dataframe\n",
    "pd.set_option('max_colwidth', -1)# To set the width of the column to maximum\n",
    "\n",
    "import itertools # confusion matrix\n",
    "import string\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import bs4\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier,LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_cloud(X, class_name):\n",
    "    plt.figure(figsize = (20,20)) \n",
    "    wc = WordCloud(max_words = 500 , width = 1600 , height = 800).generate(\" \".join(X.review))\n",
    "    plt.imshow(wc , interpolation = 'bilinear')\n",
    "    plt.title(f'Word cloud for {class_name}',fontsize=14)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset1/drugsComTrain_raw.tsv', sep='\\t')\n",
    "df.to_csv('dataset1/drugsComTrain.csv',index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[(df['condition']=='Birth Control') | (df['condition']=='Depression') | (df['condition']=='High Blood Pressure')|(df['condition']=='Diabetes, Type 2')]\n",
    "X = df_train.drop(['Unnamed: 0','drugName','rating','date','usefulCount'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregating dataframe for analyzing individual condition\n",
    "X_birth=X[(X['condition']=='Birth Control')]\n",
    "X_dep=X[(X['condition']=='Depression')]\n",
    "X_bp=X[(X['condition']=='High Blood Pressure')]\n",
    "X_diab=X[(X['condition']=='Diabetes, Type 2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(X_birth, 'Birth Control')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(X_dep, 'Depression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(X_bp, 'High Blood Pressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud(X_diab, 'Diabetes Type 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text() # delete html\n",
    "    \n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)# make a space\n",
    "    \n",
    "    words = letters_only.lower().split()# lower letters\n",
    "    \n",
    "    meaningful_words = [w for w in words if not w in stopwords.words('english')]# delete stopwords\n",
    "    \n",
    "    lemmitize_words = [WordNetLemmatizer().lemmatize(w) for w in meaningful_words]# lemmitization\n",
    "    \n",
    "    return( ' '.join(lemmitize_words))# space join words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['review_clean'] = X['review'].apply(review_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat=X['review_clean']\n",
    "y=X['condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_feat, y, stratify=y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(count_train, y_train)\n",
    "pred = mnb.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])\n",
    "plot_confusion_matrix(cm, classes=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive = PassiveAggressiveClassifier()\n",
    "passive.fit(count_train, y_train)\n",
    "pred = passive.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])\n",
    "plot_confusion_matrix(cm, classes=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "tfidf_train_2 = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test_2 = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_tf = MultinomialNB()\n",
    "mnb_tf.fit(tfidf_train_2, y_train)\n",
    "pred = mnb_tf.predict(tfidf_test_2)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])\n",
    "plot_confusion_matrix(cm, classes=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "pass_tf = PassiveAggressiveClassifier()\n",
    "pass_tf.fit(tfidf_train, y_train)\n",
    "pred = pass_tf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])\n",
    "plot_confusion_matrix(cm, classes=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF: Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer2 = TfidfVectorizer(stop_words='english', max_df=0.8, ngram_range=(1,2))\n",
    "tfidf_train_2 = tfidf_vectorizer2.fit_transform(X_train)\n",
    "tfidf_test_2 = tfidf_vectorizer2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_tf = PassiveAggressiveClassifier()\n",
    "pass_tf.fit(tfidf_train_2, y_train)\n",
    "pred = pass_tf.predict(tfidf_test_2)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])\n",
    "plot_confusion_matrix(cm, classes=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF : Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer3 = TfidfVectorizer(stop_words='english', max_df=0.8, ngram_range=(1,3))\n",
    "tfidf_train_3 = tfidf_vectorizer3.fit_transform(X_train)\n",
    "tfidf_test_3 = tfidf_vectorizer3.transform(X_test)\n",
    "\n",
    "pass_tf = PassiveAggressiveClassifier()\n",
    "pass_tf.fit(tfidf_train_3, y_train)\n",
    "pred = pass_tf.predict(tfidf_test_3)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])\n",
    "plot_confusion_matrix(cm, classes=['Birth Control', 'Depression','Diabetes, Type 2','High Blood Pressure'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_informative_feature_for_class(vectorizer, classifier, classlabel, n=10):\n",
    "    labelid = list(classifier.classes_).index(classlabel)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topn = sorted(zip(classifier.coef_[labelid], feature_names))[-n:]\n",
    "\n",
    "    for coef, feat in topn:\n",
    "        print (classlabel, feat, coef)\n",
    "\n",
    "\n",
    "\n",
    "most_informative_feature_for_class(tfidf_vectorizer2, pass_tf, 'Birth Control')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_informative_feature_for_class(tfidf_vectorizer2, pass_tf, 'Depression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_informative_feature_for_class(tfidf_vectorizer2, pass_tf, 'High Blood Pressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_informative_feature_for_class(tfidf_vectorizer2, pass_tf, 'Diabetes, Type 2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for Extracting Top drugs\n",
    "\n",
    "def top_drugs_extractor(condition):\n",
    "    df_top = df[(df['rating']>=9)&(df['usefulCount']>=100)].sort_values(by = ['rating', 'usefulCount'], ascending = [False, False])\n",
    "    drug_lst = df_top[df_top['condition']==condition]['drugName'].head(3).tolist()\n",
    "    return drug_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(lst_text):\n",
    "    df_test = pd.DataFrame(lst_text, columns = ['test_sent'])\n",
    "    df_test[\"test_sent\"] = df_test[\"test_sent\"].apply(review_to_words)\n",
    "    tfidf_bigram = tfidf_vectorizer3.transform(lst_text)\n",
    "    prediction = pass_tf.predict(tfidf_bigram)\n",
    "    df_test['prediction']=prediction\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  \"I have only been on Tekturna for 9 days. The effect was immediate. I am also on a calcium channel blocker (Tiazac) and hydrochlorothiazide. I was put on Tekturna because of palpitations experienced with Diovan (ugly drug in my opinion, same company produces both however). The palpitations were pretty bad on Diovan, 24 hour monitor by EKG etc. After a few days of substituting Tekturna for Diovan, there are no more palpitations.\",\n",
    "    \"This is the third med I&#039;ve tried for anxiety and mild depression. Been on it for a week and I hate it so much. I am so dizzy, I have major diarrhea and feel worse than I started. Contacting my doc in the am and changing asap.\",\n",
    "    \"I just got diagnosed with type 2. My doctor prescribed Invokana and metformin from the beginning. My sugars went down to normal by the second week. I am losing so much weight. No side effects yet. Miracle medicine for me\",\n",
    "    \n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_trigram = tfidf_vectorizer3.transform(sentences)\n",
    "\n",
    "\n",
    "predictions = pass_tf.predict(tfidf_trigram)\n",
    "\n",
    "for text, label in zip(sentences, predictions):\n",
    "    if label==\"High Blood Pressure\":\n",
    "        target=\"High Blood Pressure\"\n",
    "        top_drugs = top_drugs_extractor(label)\n",
    "        print(\"text:\", text, \"\\nCondition:\", target)\n",
    "        print(\"Top 3 Suggested Drugs:\")\n",
    "        print(top_drugs[0])\n",
    "        print(top_drugs[1])\n",
    "        print(top_drugs[2])\n",
    "        print()\n",
    "    elif label==\"Depression\":\n",
    "        target=\"Depression\"\n",
    "        top_drugs = top_drugs_extractor(label)\n",
    "        print(\"text:\", text, \"\\nCondition:\", target)\n",
    "        print(\"Top 3 Suggested Drugs:\")\n",
    "        print(top_drugs[0])\n",
    "        print(top_drugs[1])\n",
    "        print(top_drugs[2])\n",
    "        print()\n",
    "    elif label==\"Diabetes, Type 2\":\n",
    "        target=\"Diabetes, Type 2\"\n",
    "        top_drugs = top_drugs_extractor(label)\n",
    "        print(\"text:\", text, \"\\nCondition:\", target)\n",
    "        print(\"Top 3 Suggested Drugs:\")\n",
    "        print(top_drugs[0])\n",
    "        print(top_drugs[1])\n",
    "        print(top_drugs[2])\n",
    "        print()\n",
    "    else:\n",
    "        target=\"Birth Control\"\n",
    "        print(\"text:\", text, \"\\Condition:\", target)\n",
    "        top_drugs = top_drugs_extractor(label)\n",
    "        print(\"text:\", text, \"\\nCondition:\", target)\n",
    "        print(\"Top 3 Suggested Drugs:\")\n",
    "        print(top_drugs[0])\n",
    "        print(top_drugs[1])\n",
    "        print(top_drugs[2])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testsent = predict_text(sentences)\n",
    "df_testsent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tfidf_vectorizer3, 'tfidfvectorizer.pkl')\n",
    "joblib.dump(pass_tf, 'passmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('tfidfvectorizer.pkl')\n",
    "model = joblib.load('passmodel.pkl')\n",
    "\n",
    "test = model.predict(vectorizer.transform([\"I have only been on Tekturna for 9 days. The effect was immediate. I am also on a calcium channel blocker (Tiazac) and hydrochlorothiazide. I was put on Tekturna because of palpitations experienced with Diovan (ugly drug in my opinion, same company produces both however). The palpitations were pretty bad on Diovan, 24 hour monitor by EKG etc. After a few days of substituting Tekturna for Diovan, there are no more palpitations\"]))\n",
    "test[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
